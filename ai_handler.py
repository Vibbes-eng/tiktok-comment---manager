# ai_handler.py - Module pour g√©rer les appels OpenAI
import os
import json
import logging
from typing import List, Dict
from openai import OpenAI

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIResponseGenerator:
    """
    Classe pour g√©n√©rer des r√©ponses IA aux commentaires TikTok
    """
    
    def __init__(self):
        """Initialiser le client OpenAI"""
        # IMPORTANT: Stocker la cl√© API dans une variable d'environnement
        api_key = os.getenv("OPENAI_API_KEY")
        
        if not api_key:
            raise ValueError(
                "‚ö†Ô∏è OPENAI_API_KEY non trouv√©e. "
                "D√©finissez la variable d'environnement: export OPENAI_API_KEY='sk-...'"
            )
        
        self.client = OpenAI(api_key=api_key)
        self.model = os.getenv("OPENAI_MODEL", "gpt-4")
        logger.info(f"‚úÖ Client OpenAI initialis√© (mod√®le: {self.model})")
    
    def generate_batch_responses(
        self, 
        comments_data: List[Dict], 
        video_title: str, 
        hashtags: List[str]
    ) -> List[str]:
        """
        G√©n√©rer des r√©ponses IA pour tous les commentaires en un seul appel
        
        Args:
            comments_data: Liste des commentaires [{username, comment_text}, ...]
            video_title: Titre de la vid√©o
            hashtags: Liste des hashtags
            
        Returns:
            List[str]: Liste des r√©ponses IA correspondantes
        """
        if not comments_data:
            logger.warning("Aucun commentaire √† traiter")
            return []
        
        try:
            logger.info(f"ü§ñ G√©n√©ration de {len(comments_data)} r√©ponses IA...")
            
            # Construire le prompt batch
            prompt = self._build_batch_prompt(comments_data, video_title, hashtags)
            
            # Appeler l'API OpenAI
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": "Tu es un assistant qui retourne uniquement du JSON valide."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                max_tokens=4000,
                temperature=0.7,
            )
            
            # Parser la r√©ponse JSON
            response_text = response.choices[0].message.content.strip()
            logger.info(f"üì• R√©ponse API re√ßue ({len(response_text)} caract√®res)")
            
            # Nettoyer et parser le JSON
            parsed_responses = self._parse_json_response(response_text)
            
            if len(parsed_responses) != len(comments_data):
                logger.warning(
                    f"‚ö†Ô∏è Nombre de r√©ponses ({len(parsed_responses)}) "
                    f"diff√©rent du nombre de commentaires ({len(comments_data)})"
                )
            
            logger.info(f"‚úÖ {len(parsed_responses)} r√©ponses g√©n√©r√©es avec succ√®s")
            return parsed_responses
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration r√©ponses IA: {e}")
            # Retourner des r√©ponses par d√©faut en cas d'erreur
            return [
                "Salam! Merci pour ton commentaire üíï" 
                for _ in comments_data
            ]
    
    def _build_batch_prompt(
        self, 
        comments_data: List[Dict], 
        video_title: str, 
        hashtags: List[str]
    ) -> str:
        """Construire le prompt pour le batch de commentaires"""
        
        hashtags_str = ', '.join(hashtags) if hashtags else 'Aucun hashtag'
        
        prompt = f"""Tu es Copywriter GPT, un copywriter chaleureux et empathique pour TikTok. Tu r√©ponds aux commentaires sur les vid√©os de "Soeur Bon Plan üéÄ", une cr√©atrice de contenu lifestyle musulmane.

CONTEXTE DE LA VID√âO:
- Titre: '{video_title}'
- Hashtags: {hashtags_str}
- Audience cible: Communaut√© musulmane f√©minine sur TikTok
- Objectif: Cr√©er de l'engagement authentique et chaleureux

INSTRUCTIONS IMPORTANTES:
- R√©ponds √† chaque commentaire avec MAXIMUM 114 caract√®res
- Commence par "Salam [nom]" ou simplement "Salam" si le nom est long
- Ton chaleureux, amical, comme une grande s≈ìur bienveillante
- Utilise des expressions musulmanes l√©g√®res (hamdoulillah, inshallah, Macha'Allah, Amine) de fa√ßon naturelle
- Ne donne JAMAIS de conseils m√©dicaux, juridiques ou religieux pr√©cis
- √âvite les questions ouvertes qui cr√©ent des d√©bats
- Reste positive, encourageante et authentique
- Utilise des emojis appropri√©s (üíï üéÄ ‚ú® üíñ) mais avec mod√©ration

COMMENTAIRES √Ä TRAITER:
"""
        
        # Ajouter chaque commentaire
        for i, comment in enumerate(comments_data, 1):
            prompt += f"\n{i}. Utilisateur: {comment['username']} | Commentaire: \"{comment['comment_text']}\""
        
        prompt += """

R√âPONSE ATTENDUE:
Retourne UNIQUEMENT un JSON valide avec ce format exact (sans markdown, sans backticks):
{
    "responses": [
        {"comment_id": 1, "username": "nom_utilisateur", "comment_text": "texte_commentaire", "chatgpt_response": "ta_r√©ponse_114_chars_max"},
        {"comment_id": 2, "username": "nom_utilisateur", "comment_text": "texte_commentaire", "chatgpt_response": "ta_r√©ponse_114_chars_max"}
    ]
}

RAPPEL CRITIQUE: Chaque r√©ponse doit faire MAXIMUM 114 caract√®res!
"""
        
        return prompt
    
    def _parse_json_response(self, response_text: str) -> List[str]:
        """
        Parser la r√©ponse JSON de l'API
        
        Args:
            response_text: Texte brut de la r√©ponse
            
        Returns:
            List[str]: Liste des r√©ponses extraites
        """
        try:
            # Nettoyer le texte (enlever les markdown backticks si pr√©sents)
            cleaned_text = response_text.strip()
            
            if "```json" in cleaned_text:
                cleaned_text = cleaned_text.split("```json")[1].split("```")[0]
            elif "```" in cleaned_text:
                cleaned_text = cleaned_text.split("```")[1].split("```")[0]
            
            cleaned_text = cleaned_text.strip()
            
            # Parser le JSON
            parsed_data = json.loads(cleaned_text)
            
            # Extraire les r√©ponses
            responses = parsed_data.get("responses", [])
            
            # Retourner uniquement les textes de r√©ponse
            return [
                item.get("chatgpt_response", "Salam! Merci üíï") 
                for item in responses
            ]
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Erreur parsing JSON: {e}")
            logger.error(f"Texte re√ßu: {response_text[:500]}...")
            raise
    
    def generate_single_response(
        self, 
        username: str, 
        comment_text: str, 
        video_title: str, 
        hashtags: List[str]
    ) -> str:
        """
        G√©n√©rer une r√©ponse unique pour un commentaire
        (Utilis√© pour les modifications manuelles)
        
        Args:
            username: Nom d'utilisateur
            comment_text: Texte du commentaire
            video_title: Titre de la vid√©o
            hashtags: Liste des hashtags
            
        Returns:
            str: R√©ponse g√©n√©r√©e
        """
        try:
            hashtags_str = ', '.join(hashtags) if hashtags else 'Aucun hashtag'
            
            prompt = f"""Tu es Copywriter GPT pour "Soeur Bon Plan üéÄ".

CONTEXTE:
- Vid√©o: '{video_title}'
- Hashtags: {hashtags_str}

COMMENTAIRE:
Utilisateur: {username}
Commentaire: "{comment_text}"

INSTRUCTIONS:
- R√©ponds en MAXIMUM 114 caract√®res
- Commence par "Salam {username}" ou "Salam"
- Ton chaleureux de grande s≈ìur
- Utilise expressions musulmanes naturelles
- Pas de conseils m√©dicaux/juridiques/religieux pr√©cis

Retourne UNIQUEMENT la r√©ponse (pas de JSON, juste le texte de la r√©ponse)."""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Tu es un copywriter TikTok chaleureux et empathique."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=150,
                temperature=0.7,
            )
            
            ai_response = response.choices[0].message.content.strip()
            
            # V√©rifier la longueur
            if len(ai_response) > 114:
                logger.warning(f"‚ö†Ô∏è R√©ponse trop longue ({len(ai_response)} chars), troncature...")
                ai_response = ai_response[:111] + "..."
            
            return ai_response
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration r√©ponse unique: {e}")
            return f"Salam {username}! Merci pour ton message üíï"
    
    def validate_response_length(self, response: str, max_length: int = 114) -> bool:
        """
        Valider que la r√©ponse respecte la limite de caract√®res
        
        Args:
            response: Texte de la r√©ponse
            max_length: Longueur maximale autoris√©e
            
        Returns:
            bool: True si valide, False sinon
        """
        return len(response) <= max_length
    
    def truncate_response(self, response: str, max_length: int = 114) -> str:
        """
        Tronquer une r√©ponse si elle d√©passe la limite
        
        Args:
            response: Texte de la r√©ponse
            max_length: Longueur maximale
            
        Returns:
            str: R√©ponse tronqu√©e
        """
        if len(response) <= max_length:
            return response
        
        return response[:max_length - 3] + "..."

# Test unitaire
if __name__ == "__main__":
    # Pour tester, d√©finir OPENAI_API_KEY dans l'environnement
    # export OPENAI_API_KEY="sk-..."
    
    try:
        ai_handler = AIResponseGenerator()
        
        # Test avec quelques commentaires
        test_comments = [
            {
                'username': 'fatima_dz',
                'comment_text': 'MashaAllah super vid√©o! O√π tu as achet√© √ßa?'
            },
            {
                'username': 'muslima_paris',
                'comment_text': 'Baraka Allahou fik pour le partage ma s≈ìur'
            }
        ]
        
        video_title = "Mes bons plans du mois"
        hashtags = ['#bonplan', '#muslim', '#lifestyle']
        
        responses = ai_handler.generate_batch_responses(
            test_comments, 
            video_title, 
            hashtags
        )
        
        print("\n‚úÖ R√©ponses g√©n√©r√©es:")
        for comment, response in zip(test_comments, responses):
            print(f"\n@{comment['username']}: {comment['comment_text']}")
            print(f"‚Üí {response} ({len(response)} chars)")
        
    except Exception as e:
        print(f"‚ùå Erreur test: {e}")
        print("Assurez-vous que OPENAI_API_KEY est d√©finie dans l'environnement")
